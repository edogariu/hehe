{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aaafa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224942"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "var_idxs = np.load('data/multi_var_idxs.npy')\n",
    "things_to_consider = np.sort(var_idxs[4000:])\n",
    "len(things_to_consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75617b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105942, 224942)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import SparseDataset\n",
    "\n",
    "d = SparseDataset('all', 'multi')\n",
    "x = d.inputs_npz[:, things_to_consider]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63dd9cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=4000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "p = TruncatedSVD(n_components=4000)\n",
    "p.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f76bb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = pk.load(open('pkls/multi_4000_pca.pkl', 'rb'))\n",
    "p2.transform(x[2].toarray()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2126919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "pk.dump(p, open(\"multi_4000_pca.pkl\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb790935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(x.shape[0]):\n",
    "    z = x[i].toarray()\n",
    "    print(p.transform(z).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "multi_keys = list(pd.read_hdf('data/train_multi_inputs.h5', start=0, stop=1).keys())\n",
    "cite_keys = list(pd.read_hdf('data/train_multi_targets.h5', start=0, stop=1).keys())\n",
    "with open('pkls/coding_map.pkl', 'rb') as f:\n",
    "    rna_coders = pickle.load(f)\n",
    "    \n",
    "dna_coders = {k: [] for k in multi_keys}\n",
    "for c in cite_keys:\n",
    "    for d in rna_coders[c]:\n",
    "        dna_coders[d].append(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae46aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import SparseDataset\n",
    "\n",
    "idx = np.load('pkls/cite_best_idxs.npy')[4]\n",
    "gene = cite_keys[idx]\n",
    "dna_idxs = [multi_keys.index(s) for s in rna_coders[gene]]\n",
    "dna_idx = dna_idxs[0]\n",
    "\n",
    "# d = SparseDataset('train', 'multi')\n",
    "\n",
    "x = d.inputs_npz[:, 170000:180000].toarray()\n",
    "y = d.targets_npz[:, idx].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd547426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import tqdm\n",
    "\n",
    "xs = []\n",
    "scores = []\n",
    "for i in tqdm.tqdm(range(x.shape[1])):\n",
    "    xs.append(170000 + i)\n",
    "    x_i = x[:, i:i+1]\n",
    "    p = LinearRegression()\n",
    "    p.fit(x_i, y)\n",
    "    scores.append(p.score(x_i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(xs, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f281cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75290f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for v in dna_coders.values():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "already_seen = set()\n",
    "ret = []  # list of tuples of sets\n",
    "for k, v in tqdm.tqdm(rna_coders.items()):\n",
    "    if k in already_seen or len(v) == 0: \n",
    "        continue\n",
    "    \n",
    "    curr = [set(), set()]\n",
    "#     idx = 0\n",
    "#     curr[idx].add(k)\n",
    "#     queue = [(1-idx, v)]\n",
    "#     while len(queue) > 0:\n",
    "#         idx, thing = queue.pop()\n",
    "#         for key in thing:\n",
    "#             assert (idx == 0) == ('ENSG' in key)\n",
    "#             curr[idx].add(key)\n",
    "#             d = dna_coders if idx == 1 else rna_coders\n",
    "#             l = d[key]\n",
    "#             if len(l) > 0:\n",
    "#                 queue.append((1 - idx, l))\n",
    "        \n",
    "    \n",
    "    curr[0].add(k)\n",
    "    for dna in v:\n",
    "        curr[1].add(dna)\n",
    "#         for rna in dna_coders[dna]:\n",
    "#             curr[0].add(rna)\n",
    "#             for dna_2 in rna_coders[rna]:\n",
    "#                 curr[1].add(dna_2)\n",
    "#                 for rna_2 in dna_coders[dna_2]:\n",
    "#                     curr[0].add(rna_2)\n",
    "#                     for dna_3 in rna_coders[rna_2]:\n",
    "#                         curr[1].add(dna_3)\n",
    "    for rna in curr[0]:\n",
    "        already_seen.add(rna)\n",
    "                \n",
    "    ret.append(curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25512cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "bad = True\n",
    "while bad:\n",
    "    print('before: {}'.format(len(ret)))\n",
    "    bad = False\n",
    "    idxs_to_look_through = list(range(len(ret)))\n",
    "    for i, r1 in enumerate(tqdm.tqdm(ret)):\n",
    "        if i not in idxs_to_look_through: continue\n",
    "        for j in idxs_to_look_through:\n",
    "            if i == j: continue\n",
    "            r2 = ret[j]\n",
    "            if not r1[0].isdisjoint(r2[0]) or not r1[1].isdisjoint(r2[1]): \n",
    "                bad = True \n",
    "                r1[0] = r1[0].union(r2[0])\n",
    "                r1[1] = r1[1].union(r2[1])\n",
    "                idxs_to_look_through.remove(j)\n",
    "    ret = [ret[i] for i in idxs_to_look_through]\n",
    "    print('after: {}'.format(len(ret)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_count = 0\n",
    "dna_count = 0\n",
    "for r in ret:\n",
    "    rna_count += len(r[0])\n",
    "    dna_count += len(r[1])\n",
    "print(rna_count, dna_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f7dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for k in rna_coders.keys():\n",
    "    if len(rna_coders[k]) == 1:\n",
    "        i += 1\n",
    "print(i)\n",
    "\n",
    "i = 0\n",
    "for k in dna_coders.keys():\n",
    "    if len(dna_coders[k]) == 0:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06082417",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 5\n",
    "i = 0\n",
    "for r in ret:\n",
    "    if len(r[0]) >= t and len(r[1]) >= t:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad239b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n_bins=30\n",
    "\n",
    "lengths_rna = [len(r[0]) for r in ret]\n",
    "lengths_dna = [len(r[1]) for r in ret]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "axs[0].hist(lengths_rna, bins=n_bins)\n",
    "axs[1].hist(lengths_dna, bins=n_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(dna_coders[k]) for k in dna_coders.keys()]\n",
    "lengths = np.argsort(lengths)[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f94c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pkls/partition.pkl', 'wb') as f:\n",
    "    pickle.dump(ret, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "champ = None\n",
    "best = 0\n",
    "for r in ret:\n",
    "    if len(r[0]) > 4:\n",
    "        if len(r[1]) > best:\n",
    "            best = len(r[1])\n",
    "            champ = r\n",
    "rna_idxs = np.sort([cite_keys.index(k) for k in champ[0]])\n",
    "dna_idxs = np.sort([multi_keys.index(k) for k in champ[1]])\n",
    "len(rna_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f971721",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cite_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05231745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "multi_keys = list(pd.read_hdf('data/train_multi_inputs.h5', start=0, stop=1).keys())\n",
    "cite_keys = list(pd.read_hdf('data/train_multi_targets.h5', start=0, stop=1).keys())\n",
    "with open('pkls/partition.pkl', 'rb') as f:\n",
    "    ret = pickle.load(f)\n",
    "    champ = None\n",
    "    best = 0\n",
    "    for r in ret:\n",
    "        if len(r[0]) > 4:\n",
    "            if len(r[1]) > best:\n",
    "                best = len(r[1])\n",
    "                champ = r\n",
    "    rna_idxs = np.sort([cite_keys.index(k) for k in champ[0]])\n",
    "    dna_idxs = np.sort([multi_keys.index(k) for k in champ[1]])\n",
    "from datasets import H5Dataset, SparseDataset\n",
    "from model import Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from utils import focal_loss, device, negative_correlation_loss\n",
    "\n",
    "# ------------------------------------- hyperparameters -------------------------------------------------\n",
    "\n",
    "batch_size = 144\n",
    "\n",
    "initial_lr = 0.02\n",
    "lr_decay_period = 4\n",
    "lr_decay_gamma = 0.5\n",
    "weight_decay = 0.0004\n",
    "\n",
    "num_epochs = 11\n",
    "eval_every = 2\n",
    "patience = 3\n",
    "num_tries = 4\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(186, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(200),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(200, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 27)\n",
    ")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# train_dataloader = SparseDataset('train', 'multi').get_dataloader(batch_size)\n",
    "# val_dataloader = SparseDataset('val', 'multi').get_dataloader(batch_size)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), initial_lr, weight_decay=weight_decay)\n",
    "for _ in range(num_epochs):\n",
    "    model.train()\n",
    "    avg_loss = 0.0\n",
    "    for x, day, y in tqdm.tqdm(train_dataloader):\n",
    "        optim.zero_grad()\n",
    "        out = model(x[:, dna_idxs].to(device))\n",
    "        y = y[:, rna_idxs].to(device)\n",
    "        loss = focal_loss(out, y)\n",
    "        loss.backward()\n",
    "        avg_loss += loss.cpu().item()\n",
    "        optim.step()\n",
    "    avg_loss /= len(train_dataloader)\n",
    "    print('train', avg_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    avg_loss = 0.0\n",
    "    for x, day, y in tqdm.tqdm(val_dataloader):\n",
    "        out = model(x[:, dna_idxs].to(device))\n",
    "        y = y[:, rna_idxs].to(device)\n",
    "        loss = focal_loss(out, y)\n",
    "        avg_loss += loss.cpu().item()\n",
    "    avg_loss /= len(val_dataloader)\n",
    "    print('val', avg_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83686988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import negative_correlation_loss\n",
    "model.eval()\n",
    "for x, day, y in tqdm.tqdm(val_dataloader):\n",
    "    out = torch.sigmoid(model(x[:, dna_idxs].to(device)))\n",
    "    y = y[:, rna_idxs].to(device)\n",
    "#     loss = torch.nn.functional.mse_loss(out, y)\n",
    "#     print((out[0, :20] > 0.97).float())\n",
    "    print(out[0, :20])\n",
    "    print((y[0, :20] != 0).float())\n",
    "    print(negative_correlation_loss(out, y))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
